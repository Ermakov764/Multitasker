# Multitasker
Техническое задание
Проект: Классификатор приоритета входящих IT-тикетов

# # 1. Введение и цель проекта
Разработать учебную систему автоматической классификации текстовых обращений в службу технической поддержки по четырём уровням приоритета: Low, Medium, High, Urgent. Система анализирует текст тикета и присваивает ему категорию срочности без участия оператора. Проект выполняется в рамках учебной дисциплины «Машинное обучение» с фокусом на воспроизводимость, интерпретируемость и соответствие поставленной задаче. Сложность архитектуры ограничена требованиями учебного задания — допускается использование только классических методов машинного обучения без применения предобученных трансформеров или облачных сервисов.

# # 2. Источник данных и структура признаков
Используется датасет с платформы Hugging Face:
Console-AI/IT-helpdesk-synthetic-tickets

Структура одной записи датасета включает следующие поля:
Поле subject — строка, заголовок тикета (например: «Fwd: URGENT — Server down»)
Поле description — строка, развёрнутое описание проблемы пользователя
Поле category — строка, тематическая категория тикета (например: «Network», «Hardware»)
Поле priority — строка, целевая метка класса со значениями: «Low», «Medium», «High», «Urgent»
Поле createdAt — строка, временная метка создания тикета в формате ISO 8601
Общий объём данных: 500 записей в сплите train. Язык текста: английский. Распределение классов ожидается несбалансированным с преобладанием классов Low и Medium.
Для построения модели используются только следующие поля:
Признаки для обучения: объединённый текст из полей subject и description
Целевая переменная: поле priority
Поля category и createdAt сохраняются в рабочем датафрейме для возможного анализа распределения приоритетов по категориям или временным периодам, но не участвуют в формировании признакового пространства модели. Это требование обусловлено учебной задачей — демонстрация способности модели выделять признаки срочности исключительно из текстового контента без опоры на структурированные метаданные.

# #  3. Подготовка текстовых данных
Текстовые поля subject и description объединяются в единый признак text по правилу:
text = subject + " " + description
Пример преобразования:
Исходные поля:
subject = «URGENT: Database failure»
description = «Production database is down since 10 AM»
Результат:
text = «URGENT: Database failure Production database is down since 10 AM»

Предобработка текста включает следующие операции:
Приведение всех символов к нижнему регистру
Сохранение пунктуации и цифр без дополнительной очистки (пунктуация может нести смысловую нагрузку, например восклицательные знаки в срочных тикетах)
Удаление стоп-слов выполняется на этапе векторизации встроенным механизмом TF-IDF, а не предварительной обработкой
Пропуски в полях subject или description отсутствуют согласно спецификации датасета. При их обнаружении применяется заполнение пустой строкой.

## 4. Функциональные требования к системе
Система реализуется в виде трёх независимых скриптов, запускаемых последовательно из командной строки.


Скрипт train.py выполняет полный цикл подготовки и обучения модели. При запуске происходит загрузка датасета из Hugging Face, объединение текстовых полей, векторизация методом TF-IDF, обучение классификатора и сохранение двух файлов в корневую директорию проекта: model.pkl (объект модели) и vectorizer.pkl (объект векторизатора). 
Скрипт выводит в консоль количество загруженных записей и распределение классов по приоритетам.
Скрипт evaluate.py загружает сохранённые файлы модели и векторизатора, повторно загружает исходный датасет, разделяет его на обучающую и тестовую выборки в соотношении 80/20 с фиксированным значением random_state=42 и стратификацией по целевой переменной. Скрипт применяет модель к тестовой выборке и выводит в консоль три метрики: точность (accuracy), взвешенную F1-меру и матрицу ошибок с подписями строк и столбцов по классам приоритета.
Скрипт predict.py предоставляет интерактивный интерфейс для ручного тестирования модели. При запуске скрипт последовательно запрашивает у пользователя заголовок тикета и описание проблемы. После получения обоих полей система объединяет их, применяет сохранённую модель и выводит предсказанный приоритет в формате строки из множества {«Low», «Medium», «High», «Urgent»}. Скрипт завершает работу после одного предсказания.


# #  5. Технические требования к алгоритмам
Векторизация текста реализуется классом TfidfVectorizer из библиотеки scikit-learn с параметрами:
max_features = 500
ngram_range = (1, 2)
stop_words = «english»
min_df = 2
lowercase = True
Параметр ngram_range установлен в (1, 2) для захвата не только отдельных слов, но и устойчивых словосочетаний, характерных для срочных ситуаций: «server down», «immediately fix», «critical issue».
Классификация реализуется мультиклассовой логистической регрессией через класс LogisticRegression с параметрами:
solver = «lbfgs»
multi_class = «multinomial»
max_iter = 1000
C = 1.0
random_state = 42
Кодирование целевой переменной выполняется через LabelEncoder без ручного указания порядка классов. Порядок определяется автоматически по алфавиту: «High», «Low», «Medium», «Urgent». 
Для интерпретации результатов сохраняется обратное преобразование через метод inverse_transform.
Разделение данных на обучающую и тестовую выборки выполняется функцией train_test_split с параметрами test_size=0.2, random_state=42, stratify=y для сохранения пропорций классов в обеих выборках.


Запрещено использование предобученных языковых моделей (BERT и производные), фреймворков глубокого обучения для построения нейросетей, ансамблевых методов без согласования с преподавателем, а также любых внешних API для классификации текста.

# #  6. Требования к структуре кодовой базы
Проект организуется в единую директорию со следующими файлами:
train.py — скрипт обучения модели
evaluate.py — скрипт оценки качества
predict.py — скрипт интерактивного предсказания
requirements.txt — список зависимостей
report.md — краткий отчёт о результатах (формируется студентом перед защитой)
Каждый Python-файл начинается с многострочного комментария docstring, описывающего назначение скрипта, порядок запуска и ожидаемый вывод. Каждый логический блок кода (загрузка данных, объединение текста, векторизация, обучение) сопровождается однострочным комментарием на русском языке, расположенным непосредственно перед блоком.
Файлы модели и векторизатора сохраняются в бинарном формате pickle с помощью модуля joblib из scikit-learn. Имена файлов фиксированы: model.pkl, vectorizer.pkl.

Содержимое файла requirements.txt:

datasets>=2.14.0
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0
# #  7. Метрики качества и критерии приёмки
Базовый уровень качества определяется значением взвешенной F1-меры на тестовой выборке не ниже 0.70. Данный порог обоснован небольшим объёмом датасета (500 записей) и ожидаемым дисбалансом классов.
Дополнительный критерий корректности: при подаче на вход текста, содержащего явные маркеры срочности (например, слово «URGENT» в заглавных буквах в заголовке), модель должна предсказывать класс «Urgent» или «High» не менее чем в 80% случаев. Проверка выполняется вручную через скрипт predict.py на трёх тестовых примерах, подготовленных студентом.
Для защиты проекта требуется подготовить таблицу из 10 наиболее значимых терминов для каждого класса приоритета. Термины извлекаются анализом коэффициентов модели: для каждого класса выбираются признаки с максимальным положительным весом в соответствующем столбце матрицы coef_. Таблица включается в отчёт report.md.
Код принимается при выполнении всех условий:
Последовательный запуск скриптов train.py → evaluate.py → predict.py завершается без ошибок
Файлы model.pkl и vectorizer.pkl создаются после запуска train.py
Вывод скрипта evaluate.py содержит все три требуемые метрики в читаемом формате
Скрипт predict.py корректно обрабатывает пользовательский ввод и возвращает строку с приоритетом
Все файлы содержат комментарии и docstring на русском языке
Результат воспроизводится на другом компьютере при установке зависимостей из requirements.txt

# # 8. Порядок выполнения проекта

День 1: Анализ данных и подготовка окружения
Загрузка датасета, вывод первых пяти записей для проверки структуры, анализ распределения классов приоритета и категорий. Установка зависимостей из файла requirements.txt. Проверка доступности всех полей в записях.

День 2: Реализация обучения
Написание скрипта train.py с полным циклом обработки: загрузка → объединение текста → векторизация → обучение → сохранение. Проверка создания файлов модели и векторизатора. Вывод распределения классов в консоль для визуального контроля дисбаланса.

День 3: Реализация оценки и интерфейса
Написание скрипта evaluate.py с расчётом метрик и форматированным выводом матрицы ошибок. Написание скрипта predict.py с интерактивным вводом двух полей и выводом предсказанного приоритета. Проверка корректности преобразования меток через LabelEncoder.

День 4: Тестирование и подготовка отчёта
Запуск полного цикла обучения и оценки, фиксация полученных метрик. Подготовка таблицы ключевых терминов для каждого класса через анализ коэффициентов модели. Формирование отчёта report.md с примерами корректных и ошибочных предсказаний, анализом наиболее значимых слов для класса «Urgent».


# #  9. Примеры ожидаемого поведения системы
Пример запуска обучения:


$ python train.py
Загружено 500 записей из датасета Console-AI/IT-helpdesk-synthetic-tickets
Распределение приоритетов: Low=210, Medium=185, High=75, Urgent=30
Модель обучена за 0.8 секунды
Файлы сохранены: model.pkl, vectorizer.pkl

Пример запуска оценки:

$ python evaluate.py
Размер тестовой выборки: 100 записей
Accuracy: 0.78
F1-score (weighted): 0.76
Матрица ошибок:
        High  Low  Medium  Urgent
High       5    0       1       0
Low        0   42       2       0
Medium     1    3      35       0
Urgent     0    0       2       4

Пример интерактивного предсказания:

$ python predict.py
Введите заголовок тикета: URGENT production server down
Введите описание тикета: All users unable to access CRM since 14:30
Предсказанный приоритет: Urgent
Основные метрики мультиклассовой классификации
Accuracy (точность) рассчитывается как доля корректно предсказанных записей ко всему объёму тестовой выборки. Эта метрика проста для интерпретации, но недостаточна при несбалансированных данных. В вашем датасете ожидается преобладание классов Low и Medium (примерно 75–80% записей), поэтому модель, всегда предсказывающая «Low», может достичь accuracy около 0.4–0.45 без реальной полезности. Используйте accuracy только как вспомогательную метрику наряду с другими показателями.


Precision (точность класса) измеряет долю корректно предсказанных записей определённого класса среди всех записей, отнесённых моделью к этому классу. Для класса «Urgent» precision показывает, насколько можно доверять предсказанию срочности: высокий precision означает, что когда модель говорит «Urgent», она редко ошибается. Низкий precision для срочных классов приведёт к ложным тревогам и неоправданному перераспределению ресурсов поддержки.


Recall (полнота класса) измеряет долю записей определённого класса, которые модель смогла корректно найти среди всех реальных записей этого класса. Для класса «Urgent» recall критически важен: низкий recall означает, что часть действительно срочных тикетов будет пропущена и обработана с задержкой. В бизнес-контексте технической поддержки ошибки второго рода (пропуск срочного тикета) обычно опаснее ошибок первого рода (ложная тревога).


F1-score объединяет precision и recall в единую гармоническую меру. Для мультиклассовой задачи используются три варианта усреднения:
Macro F1 рассчитывает F1 для каждого класса отдельно и усредняет без учёта размера класса. Этот вариант подчёркивает качество на редких классах (Urgent, High), но может завышать важность малочисленных групп.
Weighted F1 усредняет F1 каждого класса с весами, пропорциональными количеству записей в классе. Эта метрика устойчива к дисбалансу и рекомендуется как основная для вашего проекта.
Micro F1 агрегирует все истинные/ложные срабатывания по всем классам перед расчётом метрики. Эквивалентен accuracy при сбалансированных данных, поэтому менее информативен в вашем случае.
Рекомендуемый базовый уровень: weighted F1-score ≥ 0.70 на тестовой выборке.


Матрица ошибок
Матрица ошибок (confusion matrix) обязательна для анализа путаницы между классами. Особое внимание уделите следующим аспектам:
Путаница между «Urgent» и «High» допустима, так как оба класса требуют быстрой реакции.
Путаница между «Urgent/High» и «Low/Medium» критична: такие ошибки приводят к пропуску срочных инцидентов.
Путаница внутри группы несрочных классов («Low» ↔ «Medium») менее значима для бизнес-логики.
Визуализируйте матрицу в виде таблицы с подписями строк (фактический класс) и столбцов (предсказанный класс). Для защиты проекта подготовьте анализ двух-трёх типичных ошибок: почему модель спутала срочный тикет с несрочным (например, отсутствие явных маркеров вроде «URGENT» в тексте).
Рекомендуемый набор метрик для отчёта
В финальный отчёт включите следующие показатели:
Weighted F1-score как основная метрика качества
Accuracy как вспомогательная метрика
Precision и recall для каждого из четырёх классов в табличной форме
Матрица ошибок с подписями классов
Бинарные precision и recall для групп «срочные» (Urgent+High) и «несрочные» (Low+Medium)
Процент корректного распознавания явных маркеров срочности (опционально, но полезно для защиты)

# #  11. Заключение
Проект представляет собой учебную реализацию классификатора текстовых тикетов с фокусом на интерпретируемость и воспроизводимость. Использование только текстовых полей без опоры на метаданные демонстрирует способность модели выявлять признаки срочности непосредственно из языковых паттернов. Минимальная архитектура на базе TF-IDF и логистической регрессии позволяет студенту полностью объяснить каждый этап работы системы при защите проекта. Оптимизация производительности, масштабируемость и промышленная надёжность не являются критериями оценки. Основной критерий — корректность реализации и способность студента аргументированно объяснить выбор каждого компонента пайплайна.

Этапы обработки данных
1. Загрузка и первичный анализ данных
Импорт библиотек: pandas, numpy, datasets.
Загрузка датасета с Hugging Face: Console-AI/IT-helpdesk-synthetic-tickets.
Вывод первых нескольких записей для проверки структуры (head()).
Анализ распределения классов целевой переменной priority.
Проверка наличия пропусков в полях subject и description.


2. Объединение текстовых полей
Создание нового признака text по правилу:

 text = subject + " " + description
При необходимости заполнение пропусков пустой строкой (fillna('')).


3. Предобработка текста
Приведение текста к нижнему регистру.
Сохранение пунктуации и цифр.
Стоп-слова будут удаляться автоматически на этапе TF-IDF векторизации.
(Опционально) удаление лишних пробелов.


4. Векторизация текста
Использование TfidfVectorizer с параметрами:

 max_features=500
ngram_range=(1,2)
stop_words='english'
min_df=2
lowercase=True
TF-IDF преобразует текст в числовые векторы, учитывая важность слов и сочетаний слов (1- и 2-граммы).


5. Кодирование целевой переменной
Применение LabelEncoder для преобразования строковых меток priority в числа.
Сохранение объекта LabelEncoder для обратного преобразования (inverse_transform) при интерпретации предсказаний.


6. Разделение данных на обучающую и тестовую выборки
Использование train_test_split с параметрами:

 test_size=0.2
random_state=42
stratify=y
Это сохраняет пропорции классов в обучающей и тестовой выборках.


7. Обучение модели
Модель: мультиклассовая логистическая регрессия (LogisticRegression):

 solver='lbfgs'
multi_class='multinomial'
max_iter=1000
C=1.0
random_state=42
Обучение на TF-IDF представлении текста.


8. Сохранение объектов
Сохранение модели (model.pkl) и векторизатора (vectorizer.pkl) с помощью joblib.
Это обеспечивает возможность воспроизводимости и использования модели в скрипте предсказаний.


9. Оценка модели
Загрузка модели и векторизатора.
Предсказание на тестовой выборке.
Вычисление метрик:


Accuracy
Weighted F1-score
Матрица ошибок с подписями классов


(Опционально) анализ ошибок: примеры неверных предсказаний, особенно путаницы между срочными и несрочными классами.


10. Интерпретация признаков
Извлечение 10 наиболее значимых терминов для каждого класса приоритета через веса модели (coef_).
Подготовка таблицы для отчета.

